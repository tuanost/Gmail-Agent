"""
Module x·ª≠ l√Ω prompt cho ph√¢n t√≠ch email b·∫±ng AI.
Module n√†y cung c·∫•p c√°c ch·ª©c nƒÉng ƒë·ªÉ x·ª≠ l√Ω email d·ª±a tr√™n c√°c prompt t·ª´ ng∆∞·ªùi d√πng.
"""

import re
import json
import os
import logging
from typing import Dict, Any, List, Optional, Union
from datetime import datetime
from dotenv import load_dotenv

# Import l·ªõp AIModelService ƒë·ªÉ s·ª≠ d·ª•ng c√°c API m√¥ h√¨nh AI
from gmail_agent.ai_models import AIModelService

# Import c√°c h√†m c·∫ßn thi·∫øt t·ª´ email_ai
from gmail_agent.email_ai import extract_email_body

# Thi·∫øt l·∫≠p logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# T·∫£i c√°c bi·∫øn m√¥i tr∆∞·ªùng
load_dotenv()

# C·∫•u h√¨nh m√¥ h√¨nh AI m·∫∑c ƒë·ªãnh t·ª´ bi·∫øn m√¥i tr∆∞·ªùng
DEFAULT_AI_PROVIDER = os.getenv("DEFAULT_AI_PROVIDER")

def analyze_email_with_prompt(email_body: str, prompt: str) -> Dict[str, Any]:
    """
    Ph√¢n t√≠ch email d·ª±a tr√™n prompt t·ª´ ng∆∞·ªùi d√πng s·ª≠ d·ª•ng m√¥ h√¨nh AI.

    Args:
        email_body: N·ªôi dung email c·∫ßn ph√¢n t√≠ch
        prompt: C√¢u l·ªánh t·ª´ ng∆∞·ªùi d√πng m√¥ t·∫£ c√°ch ph√¢n t√≠ch

    Returns:
        K·∫øt qu·∫£ ph√¢n t√≠ch d·ª±a tr√™n prompt
    """
    logger.info(f"ƒêang ph√¢n t√≠ch email v·ªõi prompt: {prompt[:50]}...")

    try:
        # T·∫°o ƒë·ªëi t∆∞·ª£ng AIModelService v·ªõi nh√† cung c·∫•p m√¥ h√¨nh t·ª´ c·∫•u h√¨nh
        ai_service = AIModelService(model_provider=DEFAULT_AI_PROVIDER)

        # G·ª≠i n·ªôi dung email v√† prompt ƒë·∫øn m√¥ h√¨nh AI ƒë·ªÉ ph√¢n t√≠ch
        result = ai_service.analyze_email(email_body, prompt)

        # L∆∞u prompt ƒë√£ s·ª≠ d·ª•ng v√†o k·∫øt qu·∫£ ƒë·ªÉ tham kh·∫£o sau n√†y
        result["prompt_su_dung"] = prompt

        # Ki·ªÉm tra l·ªói
        if result.get("error", False):
            logger.error(f"L·ªói khi s·ª≠ d·ª•ng API AI: {result.get('message', 'L·ªói kh√¥ng x√°c ƒë·ªãnh')}")
            # Fallback: S·ª≠ d·ª•ng ph∆∞∆°ng th·ª©c ph√¢n t√≠ch c·ª•c b·ªô n·∫øu g·ªçi API th·∫•t b·∫°i
            return _legacy_analyze_email(email_body, prompt)

        logger.info("ƒê√£ ph√¢n t√≠ch email th√†nh c√¥ng")
        return result

    except Exception as e:
        logger.exception(f"L·ªói khi ph√¢n t√≠ch email v·ªõi AI: {str(e)}")
        # Fallback: S·ª≠ d·ª•ng ph∆∞∆°ng th·ª©c ph√¢n t√≠ch c·ª•c b·ªô
        return _legacy_analyze_email(email_body, prompt)

def _legacy_analyze_email(email_body: str, prompt: str) -> Dict[str, Any]:
    """
    Phi√™n b·∫£n c≈© c·ªßa h√†m ph√¢n t√≠ch email ƒë·ªÉ s·ª≠ d·ª•ng khi API AI g·∫∑p l·ªói.

    Args:
        email_body: N·ªôi dung email c·∫ßn ph√¢n t√≠ch
        prompt: Prompt ng∆∞·ªùi d√πng y√™u c·∫ßu

    Returns:
        K·∫øt qu·∫£ ph√¢n t√≠ch ƒë∆°n gi·∫£n
    """
    logger.warning("S·ª≠ d·ª•ng ph√¢n t√≠ch legacy v√¨ kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn API AI")

    # M·∫∑c ƒë·ªãnh x·ª≠ l√Ω chung
    result = {
        "prompt_su_dung": prompt,
        "phan_tich": "Kh√¥ng th·ªÉ k·∫øt n·ªëi t·ªõi API AI. ƒê√¢y l√† ph√¢n t√≠ch c·ª•c b·ªô ƒë∆°n gi·∫£n."
    }

    return result

def format_analysis_result(result: Dict[str, Any]) -> str:
    """
    ƒê·ªãnh d·∫°ng k·∫øt qu·∫£ ph√¢n t√≠ch ƒë·ªÉ hi·ªÉn th·ªã cho ng∆∞·ªùi d√πng.

    Args:
        result: K·∫øt qu·∫£ ph√¢n t√≠ch t·ª´ h√†m analyze_email_with_prompt

    Returns:
        Chu·ªói ƒë√£ ƒë·ªãnh d·∫°ng ƒë·ªÉ hi·ªÉn th·ªã
    """
    output = "===== K·∫æT QU·∫¢ PH√ÇN T√çCH EMAIL =====\n\n"

    # Hi·ªÉn th·ªã prompt ƒë∆∞·ª£c s·ª≠ d·ª•ng cho ph√¢n t√≠ch ·ªü ƒë·∫ßu k·∫øt qu·∫£
    if "prompt_su_dung" in result:
        output += "üîç PROMPT ƒê√É S·ª¨ D·ª§NG:\n"
        output += f"{result['prompt_su_dung']}\n\n"

    # Hi·ªÉn th·ªã th√¥ng tin v·ªÅ chu·ªói h·ªôi tho·∫°i n·∫øu c√≥
    if "subject" in result:
        output += f"üìß CH·ª¶ ƒê·ªÄ: {result['subject']}\n"

    if "message_count" in result:
        output += f"üìä S·ªê TIN NH·∫ÆN: {result['message_count']}\n\n"

    # Ph√¢n t√≠ch
    if "phan_tich" in result and result["phan_tich"]:
        output += "üìå PH√ÇN T√çCH:\n"
        output += _format_analysis_content(result["phan_tich"])

    # Th√™m c√°c tr∆∞·ªùng ph√¢n t√≠ch h·ªôi tho·∫°i n·∫øu c√≥
    _append_conversation_analysis(result, output)

    return output

def _format_analysis_content(content: Union[str, List[str], Dict[str, Any]]) -> str:
    """
    ƒê·ªãnh d·∫°ng n·ªôi dung ph√¢n t√≠ch d·ª±a tr√™n lo·∫°i d·ªØ li·ªáu.

    Args:
        content: N·ªôi dung ph√¢n t√≠ch (chu·ªói, danh s√°ch ho·∫∑c dictionary)

    Returns:
        Chu·ªói ƒë√£ ƒë·ªãnh d·∫°ng
    """
    formatted_output = ""

    if isinstance(content, str):
        formatted_output = content + "\n\n"
    elif isinstance(content, list):
        for item in content:
            formatted_output += f"  ‚Ä¢ {item}\n"
        formatted_output += "\n"
    elif isinstance(content, dict):
        for key, value in content.items():
            formatted_output += f"  ‚Ä¢ {key}: {value}\n"
        formatted_output += "\n"

    return formatted_output

def _append_conversation_analysis(result: Dict[str, Any], output: str) -> None:
    """
    Th√™m c√°c tr∆∞·ªùng ph√¢n t√≠ch h·ªôi tho·∫°i v√†o output n·∫øu c√≥.

    Args:
        result: K·∫øt qu·∫£ ph√¢n t√≠ch
        output: Chu·ªói output ƒë·ªÉ th√™m v√†o
    """
    conversation_fields = {
        "chu_de_chinh": "CH·ª¶ ƒê·ªÄ CH√çNH",
        "dien_bien": "DI·ªÑN BI·∫æN H·ªòI THO·∫†I",
        "nguoi_tham_gia": "NG∆Ø·ªúI THAM GIA",
        "cac_van_de": "C√ÅC V·∫§N ƒê·ªÄ",
        "ket_luan": "K·∫æT LU·∫¨N"
    }

    for field, title in conversation_fields.items():
        if field in result and result[field]:
            output += f"üìù {title}:\n"
            output += _format_analysis_content(result[field])

def save_analysis_result(result: Dict[str, Any], file_name: str) -> str:
    """
    L∆∞u k·∫øt qu·∫£ ph√¢n t√≠ch v√†o m·ªôt file JSON.

    Args:
        result: K·∫øt qu·∫£ ph√¢n t√≠ch
        file_name: T√™n file ƒë·ªÉ l∆∞u k·∫øt qu·∫£

    Returns:
        ƒê∆∞·ªùng d·∫´n ƒë·∫øn file ƒë√£ l∆∞u
    """
    # ƒê·∫£m b·∫£o th∆∞ m·ª•c t·ªìn t·∫°i
    output_dir = "email_analysis_results"
    os.makedirs(output_dir, exist_ok=True)

    file_path = os.path.join(output_dir, file_name)

    try:
        # S·∫Øp x·∫øp ƒë·ªÉ ƒë·∫£m b·∫£o prompt_su_dung n·∫±m ·ªü ƒë·∫ßu file JSON
        from collections import OrderedDict
        ordered_result = OrderedDict()

        # ƒê·∫∑t prompt_su_dung l√™n ƒë·∫ßu n·∫øu c√≥
        if "prompt_su_dung" in result:
            ordered_result["prompt_su_dung"] = result["prompt_su_dung"]

        # Th√™m c√°c tr∆∞·ªùng kh√°c v√†o OrderedDict
        for key, value in result.items():
            if key != "prompt_su_dung":  # B·ªè qua v√¨ ƒë√£ th√™m ·ªü tr√™n
                ordered_result[key] = value

        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(ordered_result, f, ensure_ascii=False, indent=2)

        logger.info(f"ƒê√£ l∆∞u k·∫øt qu·∫£ ph√¢n t√≠ch v√†o: {file_path}")
        return file_path

    except Exception as e:
        logger.error(f"L·ªói khi l∆∞u k·∫øt qu·∫£ ph√¢n t√≠ch: {str(e)}")
        return ""

def generate_analysis_filename(prefix: str = "email_analysis") -> str:
    """
    T·∫°o t√™n file c√≥ d·∫•u th·ªùi gian cho ph√¢n t√≠ch email.

    Args:
        prefix: Ti·ªÅn t·ªë cho t√™n file

    Returns:
        T√™n file c√≥ d·∫•u th·ªùi gian
    """
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    return f"{prefix}_{timestamp}.json"

def highlight_keywords_in_text(text: str, keywords: List[str]) -> str:
    """
    L√†m n·ªïi b·∫≠t t·ª´ kh√≥a trong vƒÉn b·∫£n.

    Args:
        text: VƒÉn b·∫£n c·∫ßn l√†m n·ªïi b·∫≠t
        keywords: Danh s√°ch c√°c t·ª´ kh√≥a c·∫ßn l√†m n·ªïi b·∫≠t

    Returns:
        VƒÉn b·∫£n v·ªõi c√°c t·ª´ kh√≥a ƒë∆∞·ª£c l√†m n·ªïi b·∫≠t
    """
    if not text or not keywords:
        return text

    highlighted_text = text

    for keyword in keywords:
        if len(keyword.strip()) > 2:  # B·ªè qua c√°c t·ª´ kh√≥a qu√° ng·∫Øn
            pattern = re.compile(re.escape(keyword), re.IGNORECASE)
            highlighted_text = pattern.sub(f"\033[1m\033[93m{keyword}\033[0m", highlighted_text)

    return highlighted_text
